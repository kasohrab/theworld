"""
Analyze PyTorch profiler traces and generate performance reports.

This script processes profiler traces generated by train_hf.py --profile
and generates detailed performance analysis reports.

Usage:
    python scripts/analyze_profile.py --trace_dir checkpoints/llava_pretrain_full/profile_traces
    python scripts/analyze_profile.py --trace_dir checkpoints/llava_pretrain_full/profile_traces --output report.md
"""

import argparse
import json
import os
from pathlib import Path
from typing import Dict, List, Tuple


def parse_args():
    """Parse command line arguments."""
    parser = argparse.ArgumentParser(description="Analyze PyTorch profiler traces")

    parser.add_argument(
        "--trace_dir",
        type=str,
        required=True,
        help="Directory containing profiler traces",
    )
    parser.add_argument(
        "--output",
        type=str,
        default=None,
        help="Output markdown file path (default: print to stdout)",
    )
    parser.add_argument(
        "--top_k",
        type=int,
        default=20,
        help="Number of top operations to show (default: 20)",
    )

    return parser.parse_args()


def find_trace_files(trace_dir: str) -> List[Path]:
    """Find all trace JSON files in the directory."""
    trace_path = Path(trace_dir)
    if not trace_path.exists():
        raise FileNotFoundError(f"Trace directory not found: {trace_dir}")

    # Find all .pt.trace.json files
    trace_files = list(trace_path.glob("*.pt.trace.json"))

    if not trace_files:
        raise FileNotFoundError(f"No trace files found in {trace_dir}")

    return sorted(trace_files)


def analyze_trace(trace_file: Path) -> Dict:
    """Analyze a single trace file and extract key metrics."""
    with open(trace_file, "r") as f:
        trace_data = json.load(f)

    # Extract events
    events = trace_data.get("traceEvents", [])

    # Categorize events by type
    cpu_events = []
    cuda_events = []
    memory_events = []

    for event in events:
        if event.get("cat") == "cpu_op":
            cpu_events.append(event)
        elif event.get("cat") == "cuda":
            cuda_events.append(event)
        elif event.get("cat") == "memory":
            memory_events.append(event)

    # Aggregate statistics
    operation_stats = {}

    for event in cpu_events + cuda_events:
        name = event.get("name", "Unknown")
        duration = event.get("dur", 0)  # Duration in microseconds

        if name not in operation_stats:
            operation_stats[name] = {
                "count": 0,
                "total_time_us": 0,
                "avg_time_us": 0,
            }

        operation_stats[name]["count"] += 1
        operation_stats[name]["total_time_us"] += duration

    # Calculate averages
    for name, stats in operation_stats.items():
        if stats["count"] > 0:
            stats["avg_time_us"] = stats["total_time_us"] / stats["count"]

    return {
        "trace_file": trace_file.name,
        "operation_stats": operation_stats,
        "total_cpu_events": len(cpu_events),
        "total_cuda_events": len(cuda_events),
        "total_memory_events": len(memory_events),
    }


def format_time(microseconds: float) -> str:
    """Format time in microseconds to human-readable string."""
    if microseconds < 1000:
        return f"{microseconds:.2f} Âµs"
    elif microseconds < 1_000_000:
        return f"{microseconds / 1000:.2f} ms"
    else:
        return f"{microseconds / 1_000_000:.2f} s"


def generate_report(analyses: List[Dict], top_k: int = 20) -> str:
    """Generate markdown report from trace analyses."""
    report = []

    report.append("# PyTorch Profiler Analysis Report\n")
    report.append(f"**Generated from {len(analyses)} trace file(s)**\n")

    # Aggregate stats across all traces
    all_operations = {}

    for analysis in analyses:
        for op_name, stats in analysis["operation_stats"].items():
            if op_name not in all_operations:
                all_operations[op_name] = {
                    "count": 0,
                    "total_time_us": 0,
                }

            all_operations[op_name]["count"] += stats["count"]
            all_operations[op_name]["total_time_us"] += stats["total_time_us"]

    # Calculate averages and sort by total time
    for op_name, stats in all_operations.items():
        stats["avg_time_us"] = stats["total_time_us"] / stats["count"]

    sorted_operations = sorted(all_operations.items(), key=lambda x: x[1]["total_time_us"], reverse=True)

    # Top operations by total time
    report.append(f"\n## Top {top_k} Operations by Total Time\n")
    report.append("| Rank | Operation | Total Time | Avg Time | Count |")
    report.append("|------|-----------|------------|----------|-------|")

    for i, (op_name, stats) in enumerate(sorted_operations[:top_k], 1):
        total_time = format_time(stats["total_time_us"])
        avg_time = format_time(stats["avg_time_us"])
        count = stats["count"]

        report.append(f"| {i} | `{op_name}` | {total_time} | {avg_time} | {count} |")

    # Key bottleneck identification
    report.append("\n## Identified Bottlenecks\n")

    bottleneck_keywords = {
        "Cosmos": ["cosmos", "wan", "vae", "encode"],
        "Image Processing": ["apply_chat_template", "siglip", "preprocess", "resize"],
        "Gemma Forward": ["gemma", "language_model", "forward"],
        "Attention": ["attention", "sdpa", "flash"],
        "Data Loading": ["dataloader", "collate", "batch"],
    }

    for category, keywords in bottleneck_keywords.items():
        category_ops = []
        total_category_time = 0

        for op_name, stats in sorted_operations:
            if any(keyword.lower() in op_name.lower() for keyword in keywords):
                category_ops.append((op_name, stats))
                total_category_time += stats["total_time_us"]

        if category_ops:
            report.append(f"\n### {category}")
            report.append(f"**Total time:** {format_time(total_category_time)}")
            report.append(f"**Operations:** {len(category_ops)}\n")

            report.append("| Operation | Total Time | Avg Time | Count |")
            report.append("|-----------|------------|----------|-------|")

            for op_name, stats in category_ops[:5]:  # Top 5 per category
                total_time = format_time(stats["total_time_us"])
                avg_time = format_time(stats["avg_time_us"])
                count = stats["count"]
                report.append(f"| `{op_name}` | {total_time} | {avg_time} | {count} |")

    # Summary statistics
    report.append("\n## Summary Statistics\n")

    total_time = sum(stats["total_time_us"] for _, stats in all_operations.items())
    total_operations = len(all_operations)
    total_calls = sum(stats["count"] for _, stats in all_operations.items())

    report.append(f"- **Total profiled time:** {format_time(total_time)}")
    report.append(f"- **Unique operations:** {total_operations:,}")
    report.append(f"- **Total operation calls:** {total_calls:,}")
    report.append(f"- **Trace files analyzed:** {len(analyses)}")

    # Per-trace breakdown
    report.append("\n## Per-Trace Breakdown\n")

    for analysis in analyses:
        report.append(f"\n### {analysis['trace_file']}")
        report.append(f"- CPU events: {analysis['total_cpu_events']:,}")
        report.append(f"- CUDA events: {analysis['total_cuda_events']:,}")
        report.append(f"- Memory events: {analysis['total_memory_events']:,}")

    # Recommendations
    report.append("\n## Optimization Recommendations\n")

    cosmos_time = sum(
        stats["total_time_us"]
        for op_name, stats in sorted_operations
        if any(kw in op_name.lower() for kw in ["cosmos", "vae", "encode"])
    )

    if cosmos_time > 0:
        cosmos_pct = 100 * cosmos_time / total_time
        report.append(f"\n**1. Cosmos VAE Encoding ({cosmos_pct:.1f}% of total time)**")
        report.append(f"   - Current time: {format_time(cosmos_time)}")
        report.append("   - Recommendation: Pre-compute and cache Cosmos latents offline")
        report.append("   - Expected speedup: 5-10x")

    preprocessing_time = sum(
        stats["total_time_us"]
        for op_name, stats in sorted_operations
        if any(kw in op_name.lower() for kw in ["apply_chat_template", "preprocess", "resize"])
    )

    if preprocessing_time > 0:
        preproc_pct = 100 * preprocessing_time / total_time
        report.append(f"\n**2. Image Preprocessing ({preproc_pct:.1f}% of total time)**")
        report.append(f"   - Current time: {format_time(preprocessing_time)}")
        report.append("   - Check if double image processing fix is applied")
        report.append("   - Consider caching preprocessed images")

    report.append("\n---\n")
    report.append("*View detailed traces in TensorBoard or Chrome trace viewer*\n")

    return "\n".join(report)


def main():
    """Main analysis function."""
    args = parse_args()

    print(f"Analyzing profiler traces from: {args.trace_dir}")

    # Find trace files
    try:
        trace_files = find_trace_files(args.trace_dir)
        print(f"Found {len(trace_files)} trace file(s)")
    except FileNotFoundError as e:
        print(f"Error: {e}")
        return 1

    # Analyze each trace
    analyses = []
    for trace_file in trace_files:
        print(f"  Analyzing {trace_file.name}...")
        try:
            analysis = analyze_trace(trace_file)
            analyses.append(analysis)
        except Exception as e:
            print(f"  Warning: Failed to analyze {trace_file.name}: {e}")
            continue

    if not analyses:
        print("Error: No traces could be analyzed")
        return 1

    # Generate report
    report = generate_report(analyses, top_k=args.top_k)

    # Output report
    if args.output:
        output_path = Path(args.output)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        with open(output_path, "w") as f:
            f.write(report)
        print(f"\nReport saved to: {output_path}")
    else:
        print("\n" + "=" * 80)
        print(report)
        print("=" * 80)

    print("\nAnalysis complete!")
    return 0


if __name__ == "__main__":
    exit(main())
