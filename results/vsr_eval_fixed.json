{
  "model": "kasohrab/theworld-vsr",
  "dataset": "cambridgeltl/vsr_random",
  "config": {
    "split": "test",
    "num_samples": 50,
    "max_new_tokens": 4,
    "temperature": 0.0,
    "image_folder": "/home/hice1/ksohrab3/scratch/theworld/data/images"
  },
  "results": {
    "world_steps_0": {
      "accuracy": 60.0,
      "correct": 30,
      "total": 50,
      "f1_macro": 37.5,
      "f1_weighted": 45.0,
      "f1_per_class": {
        "false_0": 0.0,
        "true_1": 75.0
      },
      "confusion_matrix": [
        [
          0,
          20
        ],
        [
          0,
          30
        ]
      ],
      "classification_report": {
        "False (0)": {
          "precision": 0.0,
          "recall": 0.0,
          "f1-score": 0.0,
          "support": 20.0
        },
        "True (1)": {
          "precision": 0.6,
          "recall": 1.0,
          "f1-score": 0.75,
          "support": 30.0
        },
        "accuracy": 0.6,
        "macro avg": {
          "precision": 0.3,
          "recall": 0.5,
          "f1-score": 0.375,
          "support": 50.0
        },
        "weighted avg": {
          "precision": 0.36,
          "recall": 0.6,
          "f1-score": 0.45,
          "support": 50.0
        }
      },
      "unparsed_count": 0
    }
  },
  "summary": {
    "mean_accuracy": 60.0,
    "configurations": 1
  }
}