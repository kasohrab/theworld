{
  "_comment": "DeepSpeed ZeRO-3 configuration for 4 GPUs without gradient checkpointing",
  "_use_case": "Full model training (all 6B params unfrozen) on 4x A100 40GB",
  "_memory_per_gpu": "26-30 GB (comfortable fit on A100 40GB)",
  "_expected_speed": "~3.5x baseline (excellent scaling)",

  "train_batch_size": "auto",
  "train_micro_batch_size_per_gpu": "auto",
  "gradient_accumulation_steps": "auto",
  "gradient_clipping": "auto",

  "bf16": {
    "enabled": "auto"
  },

  "zero_optimization": {
    "stage": 3,
    "offload_optimizer": {
      "device": "none"
    },
    "offload_param": {
      "device": "none"
    },
    "overlap_comm": true,
    "contiguous_gradients": true,
    "reduce_bucket_size": 5e8,
    "stage3_prefetch_bucket_size": 5e8,
    "stage3_param_persistence_threshold": 1e6,
    "stage3_max_live_parameters": 1e9,
    "stage3_max_reuse_distance": 1e9,
    "stage3_gather_16bit_weights_on_model_save": true
  }
}
